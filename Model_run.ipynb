{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67692667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "\n",
    "from string import digits\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c7e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"finetuned_city_scapes_gta.pth\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(model_path, class_map_path, img_path, rgb_path=False, mask_path=False, mask_type=\"bw\",save_path=False):\n",
    "    \n",
    "    if save_path:\n",
    "        save=True\n",
    "    \n",
    "    feature_extractor_inference = SegformerFeatureExtractor(do_random_crop=False, do_pad=False)\n",
    "    labels = [i for i in range(30)]\n",
    "    \n",
    "    df = pd.read_csv(class_map_path)\n",
    "    classes = df['name']\n",
    "    palette = df[['r', 'g', 'b']].values\n",
    "    id2label = classes.to_dict()\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    \n",
    "    image =  Image.open(img_path)\n",
    "    if mask_path:\n",
    "\n",
    "        mask = Image.open(mask_path)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        axs[0].imshow(image)\n",
    "        if mask_type==\"bw\":\n",
    "            axs[1].imshow(mask.convert('L'))\n",
    "        else:\n",
    "            axs[1].imshow(mask)\n",
    "        axs[0].axis('off')\n",
    "        axs[1].axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "    pixel_values = feature_extractor_inference(image, return_tensors=\"pt\").pixel_values.to(device).cuda()\n",
    "    model.eval()\n",
    "    outputs = model(pixel_values=pixel_values)\n",
    "    logits = outputs.logits.cpu()\n",
    "    upsampled_logits = nn.functional.interpolate(logits,size=image.size[::-1], mode='bilinear',align_corners=False)\n",
    "\n",
    "    seg = upsampled_logits.argmax(dim=1)[0]\n",
    "\n",
    "    color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) \n",
    "    for label, color in enumerate(palette):\n",
    "        color_seg[seg == label, :] = color\n",
    "        \n",
    "#     seg1 = np.array(mask)\n",
    "#     mask_temp = np.zeros((seg1.shape[0], seg1.shape[1], 4), dtype=np.uint8) \n",
    "#     if mask_path!=False and mask_type==\"bw\":        \n",
    "#         for label, color in enumerate(palette):\n",
    "#             mask_temp[seg1 == label, :] = color\n",
    "\n",
    "    mask_temp = color_seg\n",
    "\n",
    "    img_1 = np.array(image) * 0.5 + color_seg * 0.5\n",
    "    img_1 = img_1.astype(np.uint8)\n",
    "    \n",
    "    if save:\n",
    "        image.save(os.path.join(os.path.dirname(save_path),\"og_\"+os.path.basename(save_path)))\n",
    "        im_pil = Image.fromarray(img_1)\n",
    "        im_pil.save(save_path)\n",
    "        \n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    axs[0].imshow(img_1)\n",
    "    axs[1].imshow(mask_temp)\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08676f47",
   "metadata": {},
   "source": [
    "### To run the model on images from a directory, specify the dir path in the **rgb_img_dir** variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcd873",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rgb_img_dir = \"dataset_AnomalyTrack/images\"\n",
    "file_names = os.listdir(rgb_img_dir)\n",
    "file_full_paths = [os.path.join(rgb_img_dir,i) for i in file_names]\n",
    "class_map_path = \"class_dict_seg.txt\"\n",
    "\n",
    "for i in file_full_paths:\n",
    " \n",
    "    img_path = i    \n",
    "\n",
    "    run_model(model_path, class_map_path, img_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
